{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - NLU\n",
    "\n",
    "## Version: **Multinomial Naive Bayes**\n",
    "Student: Francesco Laiti\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the source code to build, train and evaluate a Naive Bayes-based sentiment analysis model using the scikit-learn library.\n",
    "\n",
    "This version is considered as baseline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the requirements to run correctly the notebook and load properly the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import subjectivity\n",
    "import numpy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('subjectivity')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the global constants used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLIT = 5 # default value of Stratified K-Fold function\n",
    "N_AFTER_COMMA = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lol2str(doc): # lol: list of list\n",
    "    return \" \".join([w for sent in doc for w in sent])\n",
    "\n",
    "def low2str(sent): # low: list of word\n",
    "    return \" \".join([w for w in sent])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_review_data():\n",
    "    neg = movie_reviews.paras(categories='neg')\n",
    "    pos = movie_reviews.paras(categories='pos')\n",
    "    return neg, pos\n",
    "\n",
    "def get_subjectivity_data():\n",
    "    subj = subjectivity.sents(categories='subj')\n",
    "    obj = subjectivity.sents(categories='obj')\n",
    "    return subj, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_subj_sents(classifier, vectorizer, data):\n",
    "    corpus = [low2str(d) for d in data]\n",
    "    vectors = vectorizer.transform(corpus)\n",
    "    filter_sents = classifier.predict(vectors)\n",
    "\n",
    "    sbj_sents = [d for d, estimate in zip(data, filter_sents) if estimate == 0] # 0 is assigned to subj\n",
    "\n",
    "    return sbj_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj, obj = get_subjectivity_data()\n",
    "neg, pos  = get_movie_review_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_subjectivity(subj, obj):\n",
    "    vectorizer = CountVectorizer()\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    corpus = [low2str(d) for d in subj] + [low2str(d) for d in obj]\n",
    "    labels = numpy.array([0] * len(subj) + [1] * len(obj))\n",
    "    \n",
    "    vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    scores = cross_validate(classifier, vectors, labels, cv=StratifiedKFold(n_splits=N_SPLIT) , scoring=['accuracy', 'f1'])\n",
    "    test_accuracy = numpy.array(scores['test_accuracy'])*100\n",
    "    test_f1 = numpy.array(scores['test_f1'])*100\n",
    "    print('Naive Bayes subjectivity classification')\n",
    "    print('\\taccuracy:', round(test_accuracy.mean(), N_AFTER_COMMA), '+-', round(test_accuracy.std(), N_AFTER_COMMA), \\\n",
    "            '%\\n\\tF1-score:', round(test_f1.mean(), N_AFTER_COMMA), '+-', round(test_f1.std(), N_AFTER_COMMA), '%')\n",
    "    classifier.fit(vectors, labels)\n",
    "\n",
    "    return classifier, vectorizer\n",
    "\n",
    "def train_polarity(neg, pos):\n",
    "    vectorizer = CountVectorizer()\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    corpus = [lol2str(d) for d in neg] + [lol2str(d) for d in pos]\n",
    "    labels = numpy.array([0] * len(neg) + [1] * len(pos))\n",
    "\n",
    "    vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    scores = cross_validate(classifier, vectors, labels, cv=StratifiedKFold(n_splits=N_SPLIT) , scoring=['accuracy', 'f1'])\n",
    "    test_accuracy = numpy.array(scores['test_accuracy'])*100\n",
    "    test_f1 = numpy.array(scores['test_f1'])*100\n",
    "    print('Naive Bayes subjectivity classification')\n",
    "    print('\\taccuracy:', round(test_accuracy.mean(), N_AFTER_COMMA), '+-', round(test_accuracy.std(), N_AFTER_COMMA), \\\n",
    "            '%\\n\\tF1-score:', round(test_f1.mean(), N_AFTER_COMMA), '+-', round(test_f1.std(), N_AFTER_COMMA), '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train subjectivity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes subjectivity classification\n",
      "\taccuracy: 92.0 +- 0.7 %\n",
      "\tF1-score: 91.9 +- 0.6 %\n"
     ]
    }
   ],
   "source": [
    "classifier, vectorizer = train_subjectivity(subj, obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train no-filter sents polarity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes subjectivity classification\n",
      "\taccuracy: 81.4 +- 1.4 %\n",
      "\tF1-score: 81.1 +- 1.6 %\n"
     ]
    }
   ],
   "source": [
    "train_polarity(neg, pos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train filter sents polarity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes subjectivity classification\n",
      "\taccuracy: 84.1 +- 2.1 %\n",
      "\tF1-score: 83.9 +- 2.2 %\n"
     ]
    }
   ],
   "source": [
    "neg_filtered = [filter_subj_sents(classifier, vectorizer, d) for d in neg]\n",
    "pos_filtered = [filter_subj_sents(classifier, vectorizer, d) for d in pos]\n",
    "\n",
    "train_polarity(neg_filtered, pos_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
